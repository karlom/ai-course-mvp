from fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom typing import Any, Dict\nimport os\nimport requests\nfrom generate_ppt import generate_course_ppt\nfrom dotenv import load_dotenv\nimport yaml\n\nload_dotenv()\napp = FastAPI()\n\nclass JobRequest(BaseModel):\n    jobId: str\n    payload: Dict[str, Any]\n\n# load prompt templates\nPROMPT_TPL_PATH = os.path.join(os.path.dirname(__file__), '..', 'prompt_templates.yaml')\nif os.path.exists(PROMPT_TPL_PATH):\n    with open(PROMPT_TPL_PATH, 'r', encoding='utf-8') as f:\n        PROMPT_TEMPLATES = yaml.safe_load(f)\nelse:\n    PROMPT_TEMPLATES = {}\n\n@app.post("/process_job")\ndef process_job(req: JobRequest):\n    """Minimal processing:\n    - Build prompt from payload (use prompt_templates.yaml normally)\n    - Call Siliconflow GLM (real call implemented below, requires SILICONFLOW_API_KEY)\n    - Parse result -> slides JSON\n    - Render PPTX\n    """\n    job = req.jobId\n    payload = req.payload\n    client_name = payload.get('client_name', 'client')\n\n    sf_key = os.getenv('SILICONFLOW_API_KEY', '')\n    sf_base = os.getenv('SILICONFLOW_BASE_URL', 'https://api.siliconflow.cn')\n    embedding_model = os.getenv('EMBEDDING_MODEL_NAME', 'Qwen3-Embedding-4B')\n\n    # Build outline prompt from template if available\n    outline_tpl = PROMPT_TEMPLATES.get('templates', {}).get('outline', {}).get('prompt', '')\n    prompt = outline_tpl.format(\n        client_name=client_name,\n        audience=payload.get('audience', ''),\n        audience_level=payload.get('audience_level', ''),\n        course_duration_hrs=payload.get('course_duration_hrs', 2),\n        outcomes=payload.get('outcomes', ''),\n        modules_count=payload.get('modules_count', 4)\n    ) if outline_tpl else f"为客户 {client_name} 生成一门示例课程大纲。"\n\n    headers = {'Authorization': f'Bearer {sf_key}', 'Content-Type': 'application/json'}\n\n    # Call Siliconflow chat completions (GLM-4.6). Adapted to documented API shape.\n    slides_json = []\n    try:\n        if sf_key:\n            # Example request structure for chat completions (adjust fields per your docs)\n            body = {\n                "model": "GLM-4.6",\n                "messages": [\n                    {"role": "system", "content": "你是企业培训讲师。"},\n                    {"role": "user", "content": prompt}\n                ],\n                "temperature": 0.2,\n                "max_tokens": 1500\n            }\n            resp = requests.post(f"{sf_base}/v1/chat/completions", headers=headers, json=body, timeout=60)\n            resp.raise_for_status()\n            data = resp.json()\n            text_out = ""\n            if isinstance(data, dict):\n                choices = data.get('choices', [])\n                if choices:\n                    text_out = choices[0].get('message', {}).get('content', '')\n            if text_out:\n                try:\n                    import json\n                    parsed = json.loads(text_out)\n                    slides_json = parsed.get('modules', [])\n                except Exception:\n                    lines = text_out.splitlines()\n                    for i, ln in enumerate(lines[:6]):\n                        slides_json.append({"title": ln[:40], "bullet_points": [ln[:40]], "speaker_notes": ""})\n        else:\n            slides_json = [\n                {"title": "课程介绍", "bullet_points": ["目标", "议程"], "speaker_notes": "讲师可介绍..."},\n                {"title": "模块1：痛点", "bullet_points": ["痛点1","痛点2"], "speaker_notes": "展开说明..."}\n            ]\n    except Exception as e:\n        slides_json = [\n            {"title": "生成失败示例", "bullet_points": [f"Error: {e}"], "speaker_notes": ""}\n        ]\n\n    pptx_path = generate_course_ppt(client_name, slides_json)\n    return {"success": True, "result": {"pptx_path": pptx_path, "slides": slides_json}}